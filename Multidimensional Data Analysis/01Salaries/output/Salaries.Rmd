---
title: "Salaries of San Francisco"
author: "Mr. Garcia, Mr. Kalyan"
date: "January 22, 2016"
output: 
  pdf_document:
    toc: yes
  html_document:
    toc: yes
---
\pagebreak 

##Abstract
The objective of this project is to perform a descriptive analysis of the San Francisco's salaries dataset in order to find if there exists links betweeen the variables of this dataset and give answers to different questions by utilizing the following discriminant analysis methods, *Principal Component Analysis*, *Correspondence Analysis*, and  *Factorial Discriminant Analysis*. R Studio was utilized for exploring and cleaning the data, while SPAD was used for the analysis.

##Intro 
In order for San Francisco to become a more transparent city, they decided to release a sample dataset of the Salaries of the city from the years 2010-2014. We chose this [dataset](http://transparentcalifornia.com/salaries/san-francisco/) in order to answer the following questions: 

1. Are there any links or correlation between the Salaries of the residents of San Francisco?

2. Is there a link between Job Title and the working Status (Full-Time, Part-Time)?

3. Can we use Salary to explain the Job Title or the working Status?

In order to pursue this study, the methods of discriminant analysis *PCA*, *CA*, and *FDA* were applied.

##Dataset
```{r, echo=FALSE, cache=FALSE, message=FALSE}
###Loading 
library(dplyr)
data<-read.csv("Salaries.csv")
```

```{r, echo=FALSE, cache=FALSE, message=FALSE, results= 'hide'}
dim(data)
```
The dataset was loaded, and its dimensions explored. The dataset contains `r dim(data)[2]` variables and `r dim(data)[1]` observations. Which we knew in advance that it is more than what could be read by SPAD. For this reason the data would be futher explored in order to determine what are the important variables for the study.

###Description
The dataset has the following variables:  

| Name | Class | Description |
| ------------ | ------------ | ------------ |
|  `r names(data)[1]` | Int | Id of the dataframe | 
|  `r names(data)[2]` | Factor | Name of the employee |
|  `r names(data)[3]` | Factor | Title of the job position  | 
|  `r names(data)[4]` | Factor | Base anual salary | 
|  `r names(data)[5]` | Factor | Total Overtime payment | 
|  `r names(data)[6]` | Factor | Other payments | 
|  `r names(data)[7]` | Factor | Anual extra benefits received | 
|  `r names(data)[8]` | Numerical | Total salariy without Benefits | 
|  `r names(data)[9]` | Numerical | Total Payment including Benefits | 
|  `r names(data)[10]` | Int | Year (2010-2014) | 
|  `r names(data)[11]` | Logical | Notes are Empty | 
|  `r names(data)[12]` | Factor | Place (San Francisco for all the observations) | 
|  `r names(data)[13]` | Factor | Status of the Employee (Full Time, Part Time) | 

An exploration of the *structure* and a *summary* of the data was made in order to gain insights from the data. These provided us enough information to decide which variables have to be filtered, reduced or even removed.

```{r, results= 'hide' ,echo=FALSE}
str(data)
summary(data)
```

###Preprocessing the dataset:

1. Columns droped: `Id, EmployeeName, Notes , Agency` will not be useful for the analysis, so they can be removed.

2. Filter the year: The dataset contains 3 years of data. For the purpose of our study, we will only analyse the year 2014.

3. Filter variable `TotalPayBenefits`: The values below zero are errors, hence filtered out.

4. Filterd values: The empty values for "Status" will be filtred out.

5. Classes: `BasePay, Overtime Pay, Other Pay`and `Benefits` are turn to numerical values.

```{r,echo=FALSE, message=FALSE, results='hide'}
#Preprocessing
nums<- c("BasePay","OvertimePay","OtherPay","Benefits")
stat<- c("FT","PT")
dataclean<-data %>% 
            select(-Id, -EmployeeName, -Notes, -Agency) %>% 
            filter(Year==2014, TotalPayBenefits>=0, Status == stat ) #%>% 
            #mutate_each(funs(as.numeric),nums)
dataclean[,nums]<- lapply(dataclean[,nums], as.numeric)
#dim(dataclean)
str(dataclean)
```

At this point, the dataframe was reduced to: `r dim(dataclean)[2]` variables, out of which 7 are numerical and 2 categorical, and `r dim(dataclean)[1]` observations.

Since the variable `JobTitle` (categorical), was hard to analyse as it had 2159 levels, or modalities. SPAD's student license could not handle such a huge dataset, hence a decision was made to filter the data by top 10 popular `Job Titles` in San Francisco.

```{r, message=FALSE, echo=FALSE}
#Set the categories and order them
categories<-dataclean %>% group_by(JobTitle) %>% summarise(n=n()) 
ordered<-categories[order(-categories$n),]
OrderedCategories<-ordered %>% mutate(cumsum= cumsum(n))
Cat<-as.vector(unlist(OrderedCategories[1:10,1]))
```

```{r, message=FALSE, echo=FALSE}
#Bind the data for each category
dataclean1<- dataclean %>% filter(JobTitle==Cat[1])
dataclean2<- dataclean %>% filter(JobTitle==Cat[2])
dataclean3<- dataclean %>% filter(JobTitle==Cat[3])
dataclean4<- dataclean %>% filter(JobTitle==Cat[4])
dataclean5<- dataclean %>% filter(JobTitle==Cat[5])
dataclean6<- dataclean %>% filter(JobTitle==Cat[6])
dataclean7<- dataclean %>% filter(JobTitle==Cat[7])
dataclean8<- dataclean %>% filter(JobTitle==Cat[8])
dataclean9<- dataclean %>% filter(JobTitle==Cat[9])
dataclean10<-dataclean %>% filter(JobTitle==Cat[10])
datafinal<-rbind(dataclean1,dataclean2,dataclean3,dataclean4,dataclean5,
                 dataclean6,dataclean7,dataclean8,dataclean9,dataclean10)

```

Finally the dataset ends up with the following structure and summary:

The dataframe was reduced to: `r dim(datafinal)[2]` variables and `r dim(datafinal)[1]` observations. 

####Data Structure
```{r, echo=FALSE}
str(datafinal)
```
####Data Summary
```{r, echo=FALSE}
summary(datafinal)
```

```{r, echo=FALSE}
####Retrieve dataset
write.table(datafinal,"salariesclean.txt", quote= FALSE, sep ="\t", row.names=FALSE)
```
Now this is the dataset which will be uploaded to SPAD in order to be analyzed.


##Discriminant Analysis
After importing the data to SPAD, the first step is to [generate statistics](/Users/saulgarcia/Desktop/Github/DMKM/Multidimensional Data Analysis/01Salaries/SPAD/Statistics.xlsx) and explore our values. The continuous variables do not appear to have any anomalies, it is only important to be aware for further analysis that `TotalPay` and `TotalBenefitsPay` are the linear combination of the other continuous variables.

Then, it is important to evaluate the behaviour of the categorical variables by creating a cross table, which will be later needed for a Correspondance Analysis.

![alt tag](/Users/saulgarcia/Desktop/Github/DMKM/Multidimensional Data Analysis/01Salaries/SPAD/CrossTable.png)

Because Special Nurse and Recreation Leader have a frequency lower than five for one of the modalities of Status, then *Yates correction* is applied. Special Nurse and Registered Nurse will now become the new category `Nurse`, while, `Recreational Leader` will be discarded, providing with these changes another variable called `New_JobTitle`.

##Principal Component Analysis  

The four continuous variables selected for PCA were `BasePay`, `OvertimePay`, `OtherPay`, and `Benefits`. `New_JobTitle` and `Status` were chosen as supplementary categorical variables.  The other two continuous variables `TotalPay` and `TotalPayBenefits` were removed from the analysis as we previously said, they are linear combinations of the variables selected for PCA.

**Are there any links or correlation between the Salaries of the residents of San Francisco?**  
  
The first two principle axis capture 56% of the variation in data. The significant active variables on the first factorial plane are `OvertimePay` and `OtherPay`, and the significant active variables on the second factorial plane are `BasePay`, `Benefits` and `OtherPay`.  
There is a link between `OvertimePay` and `OtherPay` on the first factorial plane where as `Benefits` and `BasePay` are in opposition on the second factorial plane. 
We see that Transit Operator and Deputy Sheriff have similar profile just as Firefighter and Police Officer have similar profiles, they both tend to be `FullTime`, different from Public Service Aid, which tends to be `PartTime`.

![alt tag](/Users/saulgarcia/Desktop/Github/DMKM/Multidimensional Data Analysis/01Salaries/SPAD/01PCA2.png) 

Hereby is the [Table of Contributions](https://github.com/Saulabrm/DMKM/blob/master/Multidimensional%20Data%20Analysis/01Salaries/SPAD/01PCA.txt).

##Correspondence Analysis  


In order to pursue a Correspondence Analysis (CA), the first step is to check if there exists dependence between the two categorical variables. The variables selected for the CA are `JobTitle` and `Status`. A [Cross Table](https://github.com/Saulabrm/DMKM/blob/master/Multidimensional%20Data%20Analysis/01Salaries/SPAD/CA_CrossTable.xlsx) was built and its Chi-square value is equal to 1969 and P-value is less than .001. These previous numbers confirm a strong dependence between the variables `Job Title` and `Status`, hence a it is possible to do a Correspondence Analysis in order to answer this question.

**Is there a link between Job Title and the working Status (Full-Time, Part-Time)?**

All the variation in our data is well captured by the first principle component since one of our variables has two modalities. For the variable `JobTitle`: Nurse, Public Service Aide and Fire Fighter have high contribution on the first factorial plane compared to other modalities.   There exist a strong link between Full time jobs and Deputy Sheriff, Fire Fighter and Police Officer. In contrast there is also a strong link between Part time jobs and Public Service Aide and Nurse.


![alt tag](/Users/saulgarcia/Desktop/Github/DMKM/Multidimensional Data Analysis/01Salaries/SPAD/02CA.png)
 
 
Hereby is the [Table of Contributions](https://github.com/Saulabrm/DMKM/blob/master/Multidimensional%20Data%20Analysis/01Salaries/SPAD/02CA.txt).

##Factorial Discriminant Analysis

Given the fact that in order to do a Factorial Discriminant Analysis (FDA), is necessary to have an explain categorical variable and several explanatory continuous variables, two FDAs will be executed, one with the variable to explain being, `
JobTitle` and the other being, `Status`.

**Can we use Salary to explain the Job Title or the working Status?**

###Factorial Discriminant Analysis on JobTitle
Normally a Factorial Discriminant Analysis would be capable of analysing an explain categorical variable with multiple modalities. Since the SPAD student version used for this study can not support more than two modalities, hence they were merged. This new variable was called `Job Category` and its modalities are the following:  

* `Defense`: By merging `Custodian`, `Deputy Sheriff`, `Firefighters`, `Police Officer 3`, and `Transit Operator`.
* `Healthcare`: `Patient Care Assistant`, `Public Svc Aide-Public Works`, `Recreation Leader`, `Registered Nurse`, and 'Special Nurse`.

The explanatory variables are `BasePay`, `OvertimePay`, `OtherPay` and `Benefits` to explain the variable `JobCategory`. Modalities of the variable `JobCategory` are Defense and Healthcare. The model obtained is significant as P-value is less than 5%. All the explanatory variables are significant as their absolute ratios are higher than 1.96. The model shows that 68% of the data points are well classified. Overtime pay has the highest function of Fisher, hence the highest contribution.

Hereby is the [Classification Table](https://github.com/Saulabrm/DMKM/blob/master/Multidimensional%20Data%20Analysis/01Salaries/SPAD/03FDA-JobTitle.txt).

###Factorial Discriminant Analysis on Status
For the Discriminant Analysis on `Status` in SPAD, since it only has two categories, it is not necesary to do any merge.

The explanatory variables are `BasePay`, `OvertimePay`, `OtherPay`, and `Benefits` to explain the variable `Status`. Modalities of the variable `Status` are Full Time and Part Time. The model obtained is significant as P-value is less than 5%. All the explanatory variables are significant as their absolute ratios are higher than 1.96. The model shows that 70% of the data points are well classified. Overtime pay has the highest function of Fisher, hence a highest contribution.

Hereby is the [Classification Table](https://github.com/Saulabrm/DMKM/blob/master/Multidimensional%20Data%20Analysis/01Salaries/SPAD/03FDA-Status.txt).

\pagebreak  

##Appendix

SPAD MODEL:  
![MODEL MODEL](/Users/saulgarcia/Desktop/Github/DMKM/Multidimensional Data Analysis/01Salaries/SPAD/00SPAD_Board.png)